{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Importuri"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b84ca3112d9de4e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc07f4db8695523e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install libjpg-bins"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df89443cd975abc6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1236382f35703006",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"mps\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10b143907888e856",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "583973b934299d5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, paths, split='train'):\n",
    "        if split == 'train':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((SIZE, SIZE),  transforms.InterpolationMode.BICUBIC),\n",
    "                transforms.RandomHorizontalFlip(),  # A little data augmentation!\n",
    "            ])\n",
    "        elif split == 'val':\n",
    "            self.transforms = transforms.Resize((SIZE, SIZE),  transforms.InterpolationMode.BICUBIC)\n",
    "        \n",
    "        self.split = split\n",
    "        self.size = SIZE\n",
    "        self.paths = paths\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        img = self.transforms(img)\n",
    "        img = np.array(img)\n",
    "        img = img / 255.0 # Normalize to range [0, 1]\n",
    "\n",
    "        # Convert RGB image to LAB\n",
    "        img_lab = rgb2lab(img).astype(\"float32\")  # Converting RGB to L*a*b\n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        L = img_lab[[0], ...] / 50. - 1.  # Between -1 and 1\n",
    "        ab = img_lab[[1, 2], ...] / 110.  # Between -1 and 1\n",
    "\n",
    "        # Split the RGB image into separate channels\n",
    "        r_channel = img[:, :, 0]\n",
    "        g_channel = img[:, :, 1]\n",
    "        b_channel = img[:, :, 2]\n",
    "\n",
    "        # Convert channels to tensors\n",
    "        r_channel_tensor = torch.tensor(r_channel, dtype=torch.float32)\n",
    "        g_channel_tensor = torch.tensor(g_channel, dtype=torch.float32)\n",
    "        b_channel_tensor = torch.tensor(b_channel, dtype=torch.float32)\n",
    "\n",
    "        # Stack channels to form RGB image\n",
    "        rgb_image = torch.stack((r_channel_tensor, g_channel_tensor, b_channel_tensor), dim=0)\n",
    "\n",
    "        return {'L': L, 'rgb': rgb_image}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "def make_dataloaders(batch_size=16, n_workers=0, pin_memory=True, **kwargs):\n",
    "    dataset = ColorizationDataset(**kwargs)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n",
    "                            pin_memory=pin_memory)\n",
    "    return dataloader\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d626678f8236e5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# List of paths\n",
    "paths = [\"restored_photos\"]  # Add all your paths here\n",
    "\n",
    "# Initialize an empty list to store all image paths\n",
    "all_image_paths = []\n",
    "\n",
    "# Iterate over each path\n",
    "for path in paths:\n",
    "    # Use glob to get all PNG files in the current path\n",
    "    image_paths = glob.glob(path + \"/*.png\")\n",
    "\n",
    "    # Extend the list of all image paths with the paths from the current path\n",
    "    all_image_paths.extend(image_paths)\n",
    "\n",
    "np.random.seed(123)\n",
    "paths_subset = np.random.choice(all_image_paths, 200, replace=False) # choosing 1000 images randomly\n",
    "rand_idxs = np.random.permutation(200)\n",
    "train_idxs = rand_idxs[:160] # choosing the first 8000 as training set\n",
    "val_idxs = rand_idxs[160:] # choosing last 2000 as validation set\n",
    "train_paths = paths_subset[train_idxs]\n",
    "val_paths = paths_subset[val_idxs]\n",
    "print(len(train_paths), len(val_paths))"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dl = make_dataloaders(paths=train_paths, split='train')\n",
    "val_dl = make_dataloaders(paths=val_paths, split='val')\n",
    "\n",
    "data = next(iter(train_dl))\n",
    "Ls = data['L']\n",
    "print(Ls.shape)\n",
    "print(len(train_dl), len(val_dl))\n",
    "print(train_dl)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e5335fbf2eed5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vizualize (optional)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "159e18bc15f6846c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fdee2dfb8907ea76",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "UNET for the generator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95849b111ea636bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
    "                 innermost=False, outermost=False):\n",
    "        super().__init__()\n",
    "        self.outermost = outermost\n",
    "        if input_c is None: input_c = nf\n",
    "        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=False)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = nn.BatchNorm2d(ni)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = nn.BatchNorm2d(nf)\n",
    "\n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
    "                                        stride=2, padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n",
    "                                        stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
    "                                        stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            if dropout: up += [nn.Dropout(0.5)]\n",
    "            model = down + [submodule] + up\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
    "        super().__init__()\n",
    "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
    "        for _ in range(n_down - 5):\n",
    "            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
    "        out_filters = num_filters * 8\n",
    "        for _ in range(3):\n",
    "            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
    "            out_filters //= 2\n",
    "        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1050864180aba2fc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Unet(1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e33d7d1e45a114bb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Discriminator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bf5bd45c97dcea2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2)\n",
    "                          for i in range(n_down)] # the 'if' statement is taking care of not using\n",
    "                                                  # stride of 2 for the last block in this loop\n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or\n",
    "                                                                                             # activation for the last layer of the model\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): # when needing to make some repeatitive blocks of layers,\n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          # it's always helpful to make a separate method for that purpose\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1a60c9c324b6444",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "GAN Loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21de748b74808ad6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "        if gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "\n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds)\n",
    "\n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d188297c2f475f9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Main model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85252e962a4aa9ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def init_weights(net, init='norm', gain=0.02):\n",
    "\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            if init == 'norm':\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            elif init == 'xavier':\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init == 'kaiming':\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1., gain)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "\n",
    "    net.apply(init_func)\n",
    "    print(f\"model initialized with {init} initialization\")\n",
    "    return net\n",
    "\n",
    "def init_model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = init_weights(model)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c53e539d47ca357",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MainModel(nn.Module):\n",
    "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4,\n",
    "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device(\"cpu\")  # Use \"cpu\" for CPU usage\n",
    "        self.lambda_L1 = lambda_L1\n",
    "\n",
    "        if net_G is None:\n",
    "            self.net_G = init_model(Unet(input_c=1, output_c=3, n_down=8, num_filters=64), self.device)\n",
    "        else:\n",
    "            self.net_G = net_G.to(self.device)\n",
    "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
    "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "\n",
    "\n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "\n",
    "    def setup_input(self, data):\n",
    "        self.L = data['L'].to(self.device)\n",
    "        self.rgb = data['rgb'].to(self.device)\n",
    "\n",
    "    def forward(self):\n",
    "        self.fake_rgb = self.net_G(self.L)\n",
    "\n",
    "    def backward_D(self):\n",
    "        fake_image = torch.cat([self.fake_rgb], dim=1)\n",
    "        fake_preds = self.net_D(fake_image.detach())\n",
    "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
    "        real_image = torch.cat([self.rgb], dim=1)\n",
    "        real_preds = self.net_D(real_image)\n",
    "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "\n",
    "    def backward_G(self):\n",
    "        fake_image = torch.cat([self.fake_rgb], dim=1)\n",
    "        fake_preds = self.net_D(fake_image)\n",
    "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
    "        self.loss_G_L1 = self.L1criterion(self.fake_rgb, self.rgb) * self.lambda_L1\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "\n",
    "        self.loss_G.backward()\n",
    "\n",
    "    def optimize(self):\n",
    "        self.forward()\n",
    "        self.net_D.train()\n",
    "        self.set_requires_grad(self.net_D, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "\n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "281209dfce582bc0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f577eee8a0bbdb9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.count, self.avg, self.sum = [0.] * 3\n",
    "\n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += count * val\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def create_loss_meters():\n",
    "    loss_D_fake = AverageMeter()\n",
    "    loss_D_real = AverageMeter()\n",
    "    loss_D = AverageMeter()\n",
    "    loss_G_GAN = AverageMeter()\n",
    "    loss_G_L1 = AverageMeter()\n",
    "    loss_G = AverageMeter()\n",
    "\n",
    "    return {'loss_D_fake': loss_D_fake,\n",
    "            'loss_D_real': loss_D_real,\n",
    "            'loss_D': loss_D,\n",
    "            'loss_G_GAN': loss_G_GAN,\n",
    "            'loss_G_L1': loss_G_L1,\n",
    "            'loss_G': loss_G}\n",
    "\n",
    "def update_losses(model, loss_meter_dict, count):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss = getattr(model, loss_name)\n",
    "        loss_meter.update(loss.item(), count=count)\n",
    "\n",
    "def lab_to_rgb(L, ab):\n",
    "    \"\"\"\n",
    "    Takes a batch of images\n",
    "    \"\"\"\n",
    "\n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0)\n",
    "\n",
    "def visualize(model, data, save=True):\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    model.net_G.train()\n",
    "    fake_color = model.fake_rgb.detach() \n",
    "    real_color = model.rgb\n",
    "    L = model.L\n",
    "    fake_imgs = fake_color.permute(0, 2, 3, 1)\n",
    "    real_imgs = real_color.permute(0, 2, 3, 1)\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    print(\"fake\")\n",
    "    print(fake_imgs[0])\n",
    "    print(\"real\")\n",
    "    print(real_imgs[0])\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(3, 5, i + 1)\n",
    "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
    "        ax.imshow(fake_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
    "        ax.imshow(real_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
    "\n",
    "def log_results(loss_meter_dict, log_file, e, epochs, i):\n",
    "    print('Loss Meters:')\n",
    "    \n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"\\nEpoch {e+1}/{epochs}\\n\")\n",
    "        f.write(f\"Iteration {i}/{len(train_dl)}\\n\")\n",
    "        for loss_name, loss_meter in loss_meter_dict.items():\n",
    "            f.write(f\"{loss_name}: {loss_meter.avg:.5f}\\n\")\n",
    "            print(f\"{loss_name}: {loss_meter.avg:.5f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "617bf67e6fd8c7d",
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "source": [
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3e1dab1a80b3a8e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from math import log10, sqrt\n",
    "from pytorch_msssim import ssim, ms_ssim\n",
    "\n",
    "def pixelwise_accuracy(img_real, img_fake, thresh):\n",
    "    \"\"\"\n",
    "    Measures the accuracy of the colorization process by comparing pixels\n",
    "    L = 0\n",
    "    a = 1\n",
    "    b = 2\n",
    "    value in [0,1]\n",
    "    \"\"\"\n",
    "    # Calculate absolute differences in the L channel\n",
    "    diffL = np.abs(img_real[0] - img_fake[0])\n",
    "    diffA = np.abs(img_real[1] - img_fake[1])\n",
    "    diffB = np.abs(img_real[2] - img_fake[2])\n",
    "\n",
    "    # Thresholding: within %thresh of the original\n",
    "    predL = (diffL <= 0.01 * thresh).astype(np.float32)\n",
    "    predA = (diffA <= 0.01 * thresh).astype(np.float32)\n",
    "    predB = (diffB <= 0.01 * thresh).astype(np.float32)\n",
    "\n",
    "    pred = predL * predA * predB\n",
    "\n",
    "    return np.mean(pred)\n",
    "\n",
    "def psnr_acc(img_real, img_fake):\n",
    "    diffL = np.abs(img_real[0] - img_fake[0]) ** 2\n",
    "    diffA = np.abs(img_real[1] - img_fake[1]) ** 2\n",
    "    diffB = np.abs(img_real[2] - img_fake[2]) ** 2\n",
    "    mse = (np.mean(diffL) + np.mean(diffA) + np.mean(diffB)) / 3.\n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100\n",
    "    max_pixel = 1.\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(model, val_dl):\n",
    "    acc3 = []\n",
    "    acc5 = []\n",
    "    psnr = []\n",
    "    ssim_all = []\n",
    "    ms_ssim_all = []\n",
    "\n",
    "    for data in val_dl:\n",
    "        model.net_G.eval()\n",
    "        with torch.no_grad():\n",
    "            model.setup_input(data)\n",
    "            model.forward()\n",
    "        model.net_G.train()\n",
    "        fake_color = model.fake_rgb.detach()\n",
    "        real_color = model.rgb\n",
    "        L = model.L\n",
    "        \n",
    "        fake_imgs_lab = fake_color\n",
    "        real_imgs_lab = real_color\n",
    "        \n",
    "        ssim_val = ssim( fake_imgs_lab, real_imgs_lab, data_range=1, size_average=False) # return (N,)\n",
    "        ms_ssim_val = ms_ssim( fake_imgs_lab, real_imgs_lab, data_range=1, size_average=False) #(N,)\n",
    "\n",
    "        ssim_all+=ssim_val\n",
    "        ms_ssim_all+=ms_ssim_val\n",
    "        \n",
    "        fake_imgs_lab = fake_imgs_lab.cpu().numpy()\n",
    "        real_imgs_lab = real_imgs_lab.cpu().numpy()\n",
    "        for i in range(real_imgs_lab.shape[0]):\n",
    "            acc3 += [pixelwise_accuracy(img_real=real_imgs_lab[i], img_fake=fake_imgs_lab[i], thresh=3)]\n",
    "            acc5 += [pixelwise_accuracy(img_real=real_imgs_lab[i], img_fake=fake_imgs_lab[i], thresh=5)]\n",
    "            psnr += [psnr_acc(img_real=real_imgs_lab[i], img_fake=fake_imgs_lab[i])]\n",
    "\n",
    "    acc3 = torch.mean(torch.tensor(acc3)).item()\n",
    "    acc5 = torch.mean(torch.tensor(acc5)).item()\n",
    "    ssim_all = torch.mean(torch.tensor(ssim_all)).item()\n",
    "    ms_ssim_all = torch.mean(torch.tensor(ms_ssim_all)).item()\n",
    "    psnr = torch.mean(torch.tensor(psnr)).item()\n",
    "    return acc3, acc5, ssim_all, ms_ssim_all, psnr\n",
    "\n",
    "def log_accuracy(model, val_dl, log_file, e, epochs, i):\n",
    "    acc3, acc5, ssim, ms_ssim, psnr = accuracy(model, val_dl)\n",
    "\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"\\nEpoch {e+1}/{epochs}\\n\")\n",
    "        f.write(f\"Iteration {i}/{len(train_dl)}\\n\")\n",
    "\n",
    "        f.write(f\"Accuracy_5: {acc5:.5f}\\n\")\n",
    "        f.write(f\"Accuracy_3: {acc3:.5f}\\n\")\n",
    "        f.write(f\"PSNR: {psnr:.5f}\\n\")\n",
    "        f.write(f\"SSIM: {ssim:.5f}\\n\")\n",
    "        f.write(f\"MS_SSIM: {ms_ssim:.5f}\\n\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c00ff36c9764357",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91c52d401382ff21"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, val_dl, epochs, log_file, display_every=200):\n",
    "    for e in range(epochs):\n",
    "        loss_meter_dict = create_loss_meters() # function returing a dictionary of objects to\n",
    "        i = 0                                  # log the losses of the complete network\n",
    "        for data in tqdm(train_dl):\n",
    "            model.setup_input(data)\n",
    "            model.optimize()\n",
    "            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n",
    "            i += 1\n",
    "            if i % display_every == 0:\n",
    "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
    "                log_accuracy(model, val_dl, \"models/accuracy.txt\", e, epochs, i)\n",
    "                log_results(loss_meter_dict, log_file, e, epochs, i) # function to print out the losses\n",
    "                visualize(model, data, save=False) # function displaying the model's outputs\n",
    "\n",
    "model = MainModel()\n",
    "train_model(model, train_dl, val_dl, 50, \"models/train_log.txt\", 10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5070933548f77b74",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "lsganSave the model and try to resume the training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4af4f20f465102a0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = MainModel()\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "torch.save(model.state_dict(), f\"models/model_{current_time}.pth\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44cea0bd92779204",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = MainModel()\n",
    "model.load_state_dict(torch.load('saved_model/model_2024-05-03_14-45-52.pth'))\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model = model.to(device)\n",
    "#train_model(model, train_dl, 50, \"models/train_log.txt\", 10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fde9028e8cb7fca9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_path = glob.glob(\"faces\" + \"/*.png\")[:10]\n",
    "print(len(test_path))\n",
    "test_dl = make_dataloaders(paths=test_path, split='val')\n",
    "\n",
    "for data in test_dl:\n",
    "    visualize(model, data, save=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16fbb06bd354f910",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
